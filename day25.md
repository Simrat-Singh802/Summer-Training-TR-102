Daily Diary – Day 25

Date: 29th July 2025

Topics Covered:

Single-Layer & Multi-Layer Perceptrons (SLP & MLP)

Artificial Neural Networks (ANNs)

What I Did Today:
Today, I dove deeper into the structure and working of neural networks by learning about Single Layer Perceptrons, Multi-Layer Perceptrons, and the general architecture of an Artificial Neural Network (ANN). This was an important step in understanding how deep learning models learn patterns from data.

Part 1: Single-Layer Perceptron (SLP)
What I Learned:
A Single-Layer Perceptron is the simplest type of neural network, consisting of only an input layer and an output layer with no hidden layers.

It is capable of solving linearly separable problems (like AND, OR logic gates).

Uses a simple activation function like step or sigmoid to classify outputs.

Limitations:
Cannot solve non-linearly separable problems (e.g., XOR problem).

Doesn’t capture complex patterns due to the lack of hidden layers.

Part 2: Multi-Layer Perceptron (MLP)
What I Learned:
A Multi-Layer Perceptron includes one or more hidden layers between input and output.

Each neuron in a layer is connected to every neuron in the next layer (fully connected).

Uses non-linear activation functions like ReLU, sigmoid, or tanh to enable the model to learn complex relationships.

Important Concepts:
Forward propagation – Data flows layer by layer with weighted inputs

Loss calculation – Measures how far predictions are from actual values

Backpropagation – Calculates gradients and updates weights using gradient descent

Advantages:
Can solve non-linear problems (e.g., XOR)

More powerful and flexible than a single-layer model

Part 3: Artificial Neural Networks (ANNs)
What I Understood:
An ANN is a group of perceptrons (layers) working together to model complex relationships.

An ANN typically has:

Input layer – receives the data

Hidden layers – extract patterns and representations

Output layer – makes the final prediction

Use Cases:
Handwriting recognition

Image classification

Predictive modeling

Sentiment analysis

Tools & Resources Used:
Theoretical notes & visual diagrams to understand network structure

Studied examples of SLP and MLP use cases

Prepared for upcoming hands-on implementation using Keras/TensorFlow

Summary:

Learned the difference between SLP (basic, limited) and MLP (advanced, powerful)

Understood how ANNs are structured and why they are the building blocks of deep learning

Built a strong conceptual base for implementing real models using libraries

