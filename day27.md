Daily Diary – Day 27

Date: 31st July 2025

Topics Covered:

Completion of Deep Learning Basics

Started working on a Deep Learning Project

What I Did Today:
Today marks an important milestone — I officially completed learning the fundamentals of deep learning, including neural networks, activation functions, forward/backward propagation, and optimization using gradient descent. After finishing the core theory and some hands-on examples, I have now begun building my first deep learning project.

Part 1: Completion of Deep Learning Core Concepts
Topics Reviewed:
Artificial Neural Networks (ANNs)

Single & Multi-layer Perceptrons

Activation functions (ReLU, Sigmoid, Tanh)

Forward and Backward Propagation

Loss functions (MSE, Cross-Entropy)

Optimizers (Gradient Descent, Adam)

Model training (epochs, batch size, learning rate)

Key Takeaway:
I now have a solid understanding of how deep learning models are structured, trained, and optimized.

I feel confident in designing, training, and evaluating basic neural networks using libraries like TensorFlow and Keras.

Part 2: Project Kickoff
What I Started:
Started working on a deep learning project to apply everything I’ve learned.

The project will likely involve a classification task (e.g., image or digit recognition).

Defined the project goal, began setting up the dataset, and planned the network architecture.

Initial Steps Completed:
Chose a dataset and problem type

Prepared a clean working environment

Sketched the model architecture and data flow

Set short-term goals for model building and testing

Observations:
Transitioning from theory to real-world application is exciting and challenging.

Building a project helps reinforce all deep learning concepts in a practical way.

Will require multiple iterations of model design, training, and tuning.

